\documentclass[12pt]{article}

% Layout
\usepackage[a4paper,includeheadfoot,margin=2.54cm]{geometry}

% Spracheinstellungen, alle Sprachen laden, letzte ist aktiv
\usepackage[english,ngerman]{babel}

% hilfreiche Pakete der AMS (American Mathematical Society) laden
\usepackage{amsmath}
\usepackage{amssymb}

% Sätze, Lemmata, ..
\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}

% Formelnummerierung
\numberwithin{equation}{section}

% moderne Literaturverwaltung mittels Biber, erstzt BibLaTeX,
% kann UTF-8
\usepackage{biblatex}
\addbibresource{Masterarbeit_Jonathan_Hellwig.bib}

% Einbinden von Grafik, neue Version
\usepackage{graphicx}

% Unterabbildungen
\usepackage{subcaption}

% TikZ ist kein Zeichenprogramm (doch)
\usepackage{tikz}

% listings bindet Code ein
\usepackage{listings}
\definecolor{hellgrau}{rgb}{0.90,0.90,0.90}
\definecolor{commentcol}{rgb}{0.0823,.4902,0.0}
\lstset{language=Python,
        basicstyle={\footnotesize\ttfamily},
        keywordstyle={\sffamily\bfseries},
        tabsize=2,
        numbers=left,
        numberstyle=\tt,
        stepnumber=1,
        numbersep=7pt,
        breaklines=true,
        frame=single,
        frameround=ffff,
        commentstyle=\color{commentcol},
        backgroundcolor=\color{hellgrau},
        literate=
  {á}{{\'a}}1 {é}{{\'e}}1 {í}{{\'i}}1 {ó}{{\'o}}1 {ú}{{\'u}}1
  {Á}{{\'A}}1 {É}{{\'E}}1 {Í}{{\'I}}1 {Ó}{{\'O}}1 {Ú}{{\'U}}1
  {à}{{\`a}}1 {è}{{\`e}}1 {ì}{{\`i}}1 {ò}{{\`o}}1 {ù}{{\`u}}1
  {À}{{\`A}}1 {È}{{\'E}}1 {Ì}{{\`I}}1 {Ò}{{\`O}}1 {Ù}{{\`U}}1
  {ä}{{\"a}}1 {ë}{{\"e}}1 {ï}{{\"i}}1 {ö}{{\"o}}1 {ü}{{\"u}}1
  {Ä}{{\"A}}1 {Ë}{{\"E}}1 {Ï}{{\"I}}1 {Ö}{{\"O}}1 {Ü}{{\"U}}1
  {â}{{\^a}}1 {ê}{{\^e}}1 {î}{{\^i}}1 {ô}{{\^o}}1 {û}{{\^u}}1
  {Â}{{\^A}}1 {Ê}{{\^E}}1 {Î}{{\^I}}1 {Ô}{{\^O}}1 {Û}{{\^U}}1
  {Ã}{{\~A}}1 {ã}{{\~a}}1 {Õ}{{\~O}}1 {õ}{{\~o}}1
  {œ}{{\oe}}1 {Œ}{{\OE}}1 {æ}{{\ae}}1 {Æ}{{\AE}}1 {ß}{{\ss}}1
  {ű}{{\H{u}}}1 {Ű}{{\H{U}}}1 {ő}{{\H{o}}}1 {Ő}{{\H{O}}}1
  {ç}{{\c c}}1 {Ç}{{\c C}}1 {ø}{{\o}}1 {å}{{\r a}}1 {Å}{{\r A}}1
  {€}{{\euro}}1 {£}{{\pounds}}1 {«}{{\guillemotleft}}1
  {»}{{\guillemotright}}1 {ñ}{{\~n}}1 {Ñ}{{\~N}}1 {¿}{{?`}}1
  {·}{{$\cdot$}}1
}

% Hyperlinks in Texten
\usepackage{hyperref}
\hypersetup{%
  pdftitle     = {Modeling of stochastic optimization algorithms with stochastic differential equations},
  pdfsubject   = {Masterarbeit von Jonathan Hellwig},
  pdfkeywords  = {Masterarbeit, neuronale Netze},
  pdfauthor    = {\textcopyright\ Jonathan Hellwig 2022},
  linkcolor    = red,     % links to same page
  urlcolor     = blue,     % links to URLs
  citecolor    = green!50!black,     % links to citations
  breaklinks   = true,       % links may (line) break
  colorlinks   = true,
  citebordercolor=0 0 0,  % color for \cite
  filebordercolor=0 0 0,
  linkbordercolor=0 0 0,
  menubordercolor=0 0 0,
  urlbordercolor=0 0 0,
  pdfhighlight=/P,   % moeglich /I, /P, ...
  pdfborder=0 0 0,   % keine Box um die Links!
}
% nützliche Kurzkommandos für natürliche, ..., reelle, .. Zahlen
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\K}{\mathbb{K}}

% ein paar dick gedruckte Buchstaben
\newcommand{\bfA}{\mathbf{A}}
\newcommand{\bfB}{\mathbf{B}}
\newcommand{\bfa}{\mathbf{a}}
\newcommand{\bfb}{\mathbf{b}}

% Beginn des Dokumentes
\begin{document}

% Titelseite
\thispagestyle{empty}

\begin{center}
  \includegraphics[height=2.3cm]{pics/MATH_de}
  \hfill
  \includegraphics[height=2.3cm]{pics/TUHH_de}
\end{center}

\vspace*{5em}

\begin{center}
  {\Huge
    \textsc{Relations between variants of stochastic gradient descent and stochastic differential equations}\\[2em]
  }
  {\LARGE
    Masterarbeit
  }

  \vspace*{2em}

  {\Large
    von\\
    Jonathan Hellwig\\
    aus Hamburg\\
    Matrikelnummer: 7381194\\
    Studiengang: Technomathematik\\
  }
\end{center}

\vfill
\begin{center}
  \today
\end{center}
\vfill

\begin{tabbing}
  % längste Zeile zuerst duplizieren, mit kill löschen
  Erstprüferin: \= Dr. Jens-Peter M. Zemke\kill
  Erstprüferin: \> Dr. Jens-Peter M. Zemke\\
  Zweitprüfer:  \> Dr. Jens-Peter M. Zemke\\
  Betreuer:     \> Dr. Jens-Peter M. Zemke\\
\end{tabbing}
\newpage
% this page intentionally left blank
\thispagestyle{empty}
\mbox{}
\newpage

\section*{Eidestattliche Erklärung}

Hiermit versichere ich an Eides statt, dass ich die vorliegende
Bachelorarbeit mit dem Titel
\begin{quote}
  „Titel der Bachelorarbeit“  
\end{quote}
selbständig und ohne unzulässige fremde Hilfe verfasst habe. Ich habe
keine anderen als die angegebenen Quellen und Hilfsmittel benutzt,
sowie wörtliche und sinngemäße Zitate kenntlich gemacht. Die Arbeit
hat in gleicher oder ähnlicher Form noch keiner Prüfungsbehörde
vorgelegen. Ich versichere, dass die eingereichte schriftliche Fassung
der auf dem beigefügten Medium gespeicherten Fassung entspricht.

\vspace*{3em}

\begin{tabbing}
  \rule{.4\textwidth}{1pt} \hspace*{.2\textwidth}
  \= \rule{.4\textwidth}{1pt} \\
  Ort, Datum \> Unterschrift
\end{tabbing}

\newpage
\mbox{}
\newpage
% TOC - Table of Contents
\tableofcontents
\newpage
\listoffigures
\newpage

\section{Motivation}
\label{sec:Motivation}
\subsection{Common activation functions}
\section{Background on Optimization}
\label{sec:Optimization}
This chapter covers the background of optimization theory. It goes into the formal definition of optimization problems, the necessary and sufficient conditions for minimizers, and covers iterative methods for obtaining such minimizers.
\subsection{Formal definition, Existence, Uniqueness}
In machine learning one is interesed in fitting a model $M$ parameterized by a set of parameters $\{(W_i,b_i)\}_{i=1}^m$ to a dataset such that the model minimizers a certain metric, where $W_i \in \mathbb{R}^{n_{i+1} \times n_i}$,$b_i \in \mathbb{R}^{n_{i+1}}$ for $i = 1,\dots,m-1$. This metric is commonly refered to as loss function. \\
The loss function $l:\mathbb{R}^n \times \mathbb{R}^n \rightarrow \mathbb{R}$ quantifies the distance between a prediciton $M(x) = \hat{y}$ and a true value $y$. In that sense, fitting a model to a dataset $\{(x_i,y_i)\}_{i=1}^n$ is defined as solving the minimization problem
\begin{equation}
  \min_{\{(W_i,b_i)\}_{i=1}^n} \frac{1}{n}\sum_{i=1}^n l(M(x_i), y_i)
\end{equation}
The selection of a loss function play an important role in the success of a machine learning model. Depending on the type of data there are many different loss function that posess different properties. \\
In the following, a more general version of the minimization problem is studied to obtain conditions for existence.
Consider the unconstrained minimization problem
\begin{equation}
  \min_{x \in \mathbb{R}^n} f(x),
\end{equation}
where $f:\mathbb{R}^n \rightarrow \mathbb{R}$.
\begin{definition}
  A value $x^\star$ is called global minimizer if 
  \begin{equation}
    f(x^\star) \leq f(x)
  \end{equation} 
  for all $x \in \mathbb{R}^n$.
\end{definition}
\begin{definition}
  A value $x^\star$ is called local minimizer if there exists an $\epsilon > 0$ such that
  \begin{equation}
    f(x^\star) \leq f(x)
  \end{equation} 
  for all $x \in \mathbb{R}^n, ||x-x^\star|| < \epsilon$.
\end{definition}

\begin{definition}
  A function $f$ is said to be L-smooth if its gradient are Lipschitz continuous, that is 
  \begin{equation}
    ||\nabla f(x) - \nabla f(y) || \leq L ||x-y||,
  \end{equation}
  for $x,y \in \mathbb{R}$.
\end{definition}

\begin{definition}
  A function $f$ is said to be convex if 
  \begin{equation}
    f(tx+(1-t)y) \leq tf(x)+(1-t)f(y),
  \end{equation}
  for all $x,y \in \mathbb{R}^n$ and $t \in [0,1]$.
\end{definition}
Obtaining global minimizers is difficult in practice. Therefore, in the following algorithms that converge to local minimizers are being considered.

Next, it remains to be answered how one can obtain a local minimizer $x^\star$ of $f$.
The following results provide some insight what sufficient and necessary conditions have to be fulfilled for local minimizer \cite{nocedal1999numerical}.
\begin{theorem}
  If $x^\star$ is a local minimizer and $f$ is continuously differentiable in an open neighborhood of $x^\star$, then $\nabla f(x^\star) = 0$.
\end{theorem}
\begin{theorem}
  If $x^\star$ is a local minimizer of $f$ and $\nabla^2 f$ exists and is continuous in an open neighborhood of $x^\star$, then $\nabla f(x^\star)$ and $\nabla^2f(x^\star)$ is positive semidefinite.
\end{theorem}
\begin{definition}
  A solution $x^\star \in S$ to the equation
  \begin{equation}
  \label{eq:StationaryPoint}
    \nabla f(x^\star) = 0
  \end{equation}
  is called stationary point.
\end{definition}
\subsection{Iterative methods}
For simple functions it is possible to determine the solution to (\ref*{eq:StationaryPoint})
in analytically form. However, state of the art neural networks contain billions of parameters. Therefore, iterative methods that approximate solution gradually are being used. The general form of an iterative scheme is given by
\begin{equation}
  x^{(k+1)} = x^{(k)} + \eta^{(k)} g^{(k)},
\end{equation}
where $\{\eta^{(k)}\}_{k=1}^\infty$ is called step size and $\{g^{(k)}\}_{k=1}^\infty$ is a sequence of descent directions. A descent direction is given by 

\begin{definition}
  An iterative method ($\{\eta^{(k)}\}_{k=1}^\infty$, $\{g^{(k)}\}_{k=1}^\infty$) is said to converge linearly if there exisits a constant $1 > C > 0$ such that 
  \begin{equation}
    \lim_{k \rightarrow \infty} \frac{||x^{(k+1)} - x^\star||}{||x^{(k)} - x^\star||} < M
  \end{equation}
  and it is said to converge sublinearly if 
  \begin{equation}
    \lim_{k \rightarrow \infty} \frac{||x^{(k+1)} - x^\star||}{||x^{(k)} - x^\star||} = 1
  \end{equation}
  holds.
\end{definition}
\subsubsection{Gradient Descent Method}
\begin{equation}  
  x^{(k+1)} = x^{(k)} - \eta^{(k)} \nabla f(x^{(k)}),
\end{equation}
Conventional convergence results require exact line search.

\cite{nesterov2003introductory}
\begin{theorem}
  Let $f$ satisfy assumptions ... and let $x^{(0)}$ be chosen such that 
  \begin{equation}
    r^{(0)} = ||x^{(k)} - x^\star|| \leq \frac{\bar{r}r^{(0)}}{\bar{r}-r^{(0)}}(1-\frac{2l}{L+3l}),
  \end{equation}
  where $\bar{r} = \frac{2l}{M}$.
\end{theorem}

\begin{theorem}
  Let $f$ be convex and L-smooth and let $\{x^{(k)}\}$ be a sequence generated by the gradient descent method. It follows that 
  \begin{equation}
    f(x^{(k)}) - f(x^\star) \leq \frac{2L||x^{(0)} - x^\star||^2}{k-1}
  \end{equation}
\end{theorem}

\begin{theorem}
  Let $f$ be L-smooth. It follows
  \begin{equation}
    \min_{k=1,\dots,N} ||\nabla f(x^{(k)})||^2 \leq \frac{L^2}{N}||x^{(0)}-x^\star||^2
  \end{equation}
\end{theorem}

\begin{theorem}
  Let $f$ be L-smooth and $\mu$-strongly convex. From a given $x^{(0)}$ and $\frac{1}{L} \geq \alpha > 0$, the iterates generated by the gradient descent method converge according to
  \begin{equation}
    ||x^{(k+1)} - x^\star ||^2 \leq (1-\alpha \mu)^{k+1}||x^{(0)} - x^star||^2
  \end{equation}
\end{theorem}
\subsubsection{Newton's method}
\begin{equation}
  x^{(k+1)} = x^{(k)} - (\nabla^2 f(x^{(k)}))^{-1}\nabla f(x^{(k)}),
\end{equation}
\subsection{Stochastic Optimization}
\label{sec:StochasticOptimization}
\begin{equation}
  x^{(k+1)} = x^{(k)} - \eta^{(k)} Z^{(k)},
\end{equation}
\subsubsection{Stochastic Gradient Descent}
% Convergence results
% Variants
% Gradient flow

\subsubsection{State of the art algorithms}
\label{sec:StateOfTheArtAlgorithms}

\section{Background SDE theory}
\label{sec:BackgroundSDETheory}
\subsection{Ito Integral}
\label{subsec:ItoIntegral}
\subsection{SDE Definition}
\label{subsec:SDEDefinition}

An Ito process 
\begin{equation}
  X_t = X_0 + \int_0^tb(s, X_s)ds + \int_0^t \sigma(s, X_s)dB_s
\end{equation}
\subsection{SDE Existence Uniqueness}
\label{subsec:SDEExistenceUniqueness}
\begin{theorem}
  Let $T > 0$ and $b(\cdot,\cdot):[0,T] \times \mathbb{R}^n \rightarrow \mathbb{R}^n$, $\sigma(\cdot,\cdot):[0,T] \times \mathbb{R}^n \rightarrow \mathbb{R}^{n \times m}$ be measureable functions satisfying 
  \begin{equation}
    |b(t,x)| + |\sigma(t,x)| \leq C(1+|x|); x \in \mathbb{R}^n, t \in [0,T]
  \end{equation}
  for some constant $C$, and such that 
  \begin{equation}
    |b(t,x) - b(t,y)| + |\sigma(t,x) - \sigma(t,y)| \leq D(|x-y|); x,y \in \mathbb{R}^n, t \in [0,T]
  \end{equation}
  for some constant $D$. Let $Z$ be a random variable which is independent of the $\sigma$-algebra $\mathcal{F}_{\infty}^{m}$ generated by $B_s(\cdot)$, $s\geq 0$ and such that 
  \begin{equation}
    E[|Z|^2] < \infty
  \end{equation}
Then the stochstic differential equation 
\begin{equation}
  dX_t = b(t,X_t)dt + \sigma(t, X_t)dB_t, 0 \leq t \leq T, X_0 = Z
\end{equation}
has a unique t-continuous solution $X_t(\omega)$ with the property that $X_t(\omega)$ is adapted to the filtration $\mathcal{F}_t^Z$ generated by $Z$ and $B_s(\cdot)$; $s \leq t$
and 
\begin{equation}
  E[\int_0^T|X_t|^2dt] < \infty.
\end{equation}

\end{theorem}
\subsection{SDE Numerical methods}
\label{subsec:SdeNumericalMethods}
There are two classes of numerical approximations for SDEs: Strong and weak approximations. 
\begin{definition}
  A time discrete approximation $\hat{X}_h$ with step size $h$ is a right continuous process with left hand limits. The approximation $\hat{X}_{n,h} = \hat{X}_h(t_n)$ is $\mathcal{F}_{t_n}$ measureable w.r.t. a time discretisation $\mathcal{T}^M_h$ and resucsively defined by a function $\psi$ such that for $n=0,1,\dots,M-1$ holds
  \begin{equation}
    \hat{X}_{n+1, h} = \psi(\hat{X}_{0,h}, \dots, \hat{X}_{n,h}, t_0, \dots, t_n, Z^1_n,\dots, Z_n^k)
  \end{equation}
  for some finite number $k$ of $\mathcal{F}_{t_{n+1}}$ measureable random variables $Z^j_n, 1 \leq j \leq k$.
\end{definition}
\begin{definition}
  A time discrete approximation $\hat{X}$ with maximum step size $h$ converges strongly to $X$ at time $T$ as $h \rightarrow 0$ if 
  \begin{equation}
    \lim_{h \rightarrow 0} \mathbb{E}(||X_T - \hat{X}(T)||) = 0.
  \end{equation}
  The time discrete approximation $\hat{X}$ converges strongly with order $p>0$ to $X$ at time $T$ as $h \rightarrow 0$ if there exists a constant $K > 0$, which does not depend on $h$, and a $\delta_0 > 0$ such that 
  \begin{equation}
    \mathbb{E}(||X_T - \hat{X}(T)||) \leq K h^p
  \end{equation}
  holds for each $h \in ]0, \delta_0[$.
\end{definition}

\begin{definition}
  A time discrete approximation $\hat{X}$ converges weakly to $X$ at time $T$ as $h \rightarrow 0$ with respect to a class $\mathcal{C}$ of test functions $f: \mathbb{R}^n \rightarrow \mathbb{R}$ if 
  \begin{equation}
    \lim_{h \rightarrow 0} |\mathbb{E}(f(X_T)) - \mathbb{E}(\hat{X}(T))| = 0.
  \end{equation}
  holds for all $f \in \mathcal{C}$.
  A time discrete approximation $\hat{X}$ converges weakly with order $p$ to $X$ at time $T$ as $h \rightarrow 0$ if ofr each $f \in C^{2(p+1)}(\mathbb{R}^n, \mathbb{R})$ there exists a constant $K_f$ and a finite $\delta_0$ such that 
  \begin{equation}
     |\mathbb{E}(f(X_T)) - \mathbb{E}(\hat{X}(T))| = K_f h^p.
  \end{equation}
  for each $h \in ]0, \delta_0[$.
\end{definition}

A commonly used time discrete scheme is the Euler-Maruyama scheme. It is given by the following recurrance relations
\begin{equation}
  X_{n+1} = X_n + b(X_n, t_n)\Delta t + \sigma(X_n, t_n) \Delta B_n
\end{equation}
for $0 \leq n \leq N$.
\section{Modeling stochastic model with SDE}

\subsection{SGD}
A class of loss function $f$ relevant to machine learning applications is usually given in the form $f(x,y) = \sum_{i=1}^n f_i(x,y)$.
\begin{equation}
  x^{(k+1)} = x^{(k)} - \psi^k \nabla f(x^{(k)}) h +  \psi(t)\sqrt{h/b^{(k)}} \sigma_{MB}(x^{(k)})Z^{(k)}
\end{equation}
\begin{equation}
  dX(t) = -\psi(t)\nabla f(X(t))dt + \psi(t)\sqrt{h/b(t)} \sigma_{MB}(X(t))dB(t)
\end{equation}
\begin{equation}
  dX(t) = -\psi(t)\nabla f(X(t))dt + \psi(t)\sqrt{h/b(t)} \sigma_{MB}(X(t), X(t-\xi(t)))dB(t)
\end{equation}
A simplified model SDE model is given by 
\begin{equation}
  dX_t = -\nabla f(X_t)dt + (\eta \Sigma(X_t))^{\frac{1}{2}}dB_t
\end{equation}
where
\begin{equation}
  \Sigma(X_t) = \frac{1}{N} \sum_{i=1}^N (\nabla f(x) - \nabla f_i(x))(\nabla f(x) - \nabla f_i(x))^T.
\end{equation}
One key observation is that the model includes the full gradient as well as a covariance term that requires the evaluation of each individual gradient term. Many commonly used numerical schemes  to obtain samples of the solution of this SDE require the evaluation of the bias $b$ and the dirft $\sigma$. For example, the Euler-Maruyama scheme introduced in seciton (\ref{subsec:SdeNumericalMethods}) requires the evaluation of $b$ and $\sigma$ in each time step. 
Additionally, the evaluation of $\sigma$ requires the storage of $n^2$ entries, where $n \in \mathbb{N}$ is the number of paramters in the model.
In (\cite*{li2021validity}) the authors indroduce the time discrete approximation called stochastic variance amplified gradient (SVAG).This method does need evaluations of the full gradient. It is given the following recurrance relation
\begin{equation}
  X_{k+1} = X_k - \frac{\eta}{l} \nabla f^l(X_k)
\end{equation}
where $f^l$ is defined as
\begin{equation}
  f^l_{i,j}(x) = \frac{1+\sqrt{2l - 1}}{2}f_i(x) + \frac{1-\sqrt{2l - 1}}{2}f_j(x).
\end{equation}
for independently sampled $i,j$.
\subsection{Generalization}
\section{Solving SDE Model}
\label{sec:SolvingSDEModel}
\subsection{Assumptions for solving}
\section{Experimental Verification} 
\label{sec:ExperimentalVerification}
\section{Conclusion}

\printbibliography
\end{document}
